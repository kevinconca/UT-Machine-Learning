\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Otto Group Product Classification Challenge}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.1}Data}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.2}Evaluation}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Research and Analysis}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data Analysis}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Maximum values per feature}}{3}}
\newlabel{fig:max_per_feature}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces t-distributed stochastic neighbor embedding}}{4}}
\newlabel{fig:Tsne}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Research}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Logistic Regression}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Logistic function $\sigma (t)$}}{5}}
\newlabel{fig:log_curve}{{3}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}K-nearest neighbor}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Random Forests}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Gradient Boosting}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementation}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Logistic Regression}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The LogisticRegression parameters}}{8}}
\newlabel{table:LRdefaults}{{1}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Results}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Grid search output}}{8}}
\newlabel{table:LR_gs}{{2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Logistic regression confusion matrix using training dataset}}{8}}
\newlabel{fig:LRcm_train}{{4}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Logistic regression confusion matrix using testing dataset}}{9}}
\newlabel{fig:LRcm_test}{{5}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}K-nearest neighbor}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The KNeighborsClassifier parameters}}{9}}
\newlabel{table:KNNdefaults}{{3}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Results}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Grid search output}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Scores varying the number of neighbors}}{10}}
\newlabel{fig:KNN_scores}{{6}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces k-NN confusion matrix using training dataset}}{11}}
\newlabel{fig:KNNcm_train}{{7}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces k-NN confusion matrix using testing dataset}}{11}}
\newlabel{fig:KNNcm_test}{{8}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Random Forests}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The RandomForestClassifier parameters}}{12}}
\newlabel{table:RFdefaults}{{5}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Results}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Grid search output}}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Performance using logarithmic loss as a metric}}{13}}
\newlabel{fig:RFlog_loss}{{9}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Performance using accuracy as a metric}}{13}}
\newlabel{fig:RFaccuracy}{{10}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Random Forests confusion matrix using training dataset}}{14}}
\newlabel{fig:RFcm_train}{{11}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Random Forests confusion matrix using testing dataset}}{14}}
\newlabel{fig:RFcm_test}{{12}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Gradient Boosting}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces The GradientBoostingClassifier parameters}}{15}}
\newlabel{table:GBdefaults}{{7}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Results}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Grid search output}}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Gradient boosting performance using logarithmic loss as a metric}}{15}}
\newlabel{fig:GBlog_loss}{{13}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Gradient boosting performance using accuracy as a metric}}{16}}
\newlabel{fig:GBaccuracy}{{14}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Gradient boosting confusion matrix using training set}}{16}}
\newlabel{fig:GBcm_train}{{15}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Gradient boosting confusion matrix using testing set}}{17}}
\newlabel{fig:GBcm_test}{{16}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Combining predictions}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Test scores per classifier}}{17}}
\newlabel{table:summaryLogLoss}{{9}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces weights obtained from minimizing $LogLoss$ function}}{18}}
\newlabel{fig:weights}{{17}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Computation time}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Overview of training and predicting times}}{18}}
\newlabel{table:times}{{10}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Stacking's schema of 2nd place winner}}{19}}
\newlabel{fig:stacking}{{18}{19}}
\bibcite{scikit_learn}{1}
\bibcite{stacking}{2}
\bibcite{ML_Alpaydm}{3}
\bibcite{kaggle}{4}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{20}}
